{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e4f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\prave\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6dbefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\prave\\anaconda3\\lib\\site-packages (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from requests) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9476c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\prave\\anaconda3\\lib\\site-packages (4.16.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from selenium) (0.23.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\prave\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\prave\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\prave\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\prave\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\prave\\anaconda3\\Lib\\site-packages\\certifi-2023.7.22.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "367918cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.edge.service import Service\n",
    "import json\n",
    "import string\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Path to your webdriver\n",
    "path_to_webdriver = \"C:/Users/prave/OneDrive/Desktop/Current_Projects/My_try1/msedgedriver.exe\"\n",
    "\n",
    "# Create a new instance of the Edge driver\n",
    "s = Service(executable_path=path_to_webdriver)\n",
    "driver = webdriver.Edge(service=s)\n",
    "\n",
    "\n",
    "# Function to sanitize file names\n",
    "def sanitize_file_name(file_name):\n",
    "    return \"\".join(c for c in file_name if c.isalnum() or c in (' ',)).rstrip()\n",
    "\n",
    "# Iterate over each letter\n",
    "for letter in string.ascii_lowercase:\n",
    "    #     element = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, f'[id=\"075c9eb4-1ba8-407c-9bb0-3a223d0b0314js-{letter}\"].js-enabled')))\n",
    "    #     element = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, f'//a[contains(@class, \"js-enabled\") and text()=\"{letter.upper()}\"]')))\n",
    "    #     element = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, f'a.js-enabled:contains(\"{letter.upper()}\")')))\n",
    "    driver.get(\"https://my.clevelandclinic.org/health/treatments\")\n",
    "\n",
    "    # EC.element_to_be_clickable\n",
    "    # EC.visibility_of_element_located\n",
    "    # Click on BROWSER A-Z\n",
    "    browser_az = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, \"js-library-search-nav__browse-btn\")))\n",
    "    browser_az.click()\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, f'//a[contains(@class, \"js-enabled\") and text()=\"{letter.upper()}\"]')))    \n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        continue\n",
    "    # Get the page source and create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Extract the links you want\n",
    "    links = soup.find_all('a', class_=\"index-list-link\")\n",
    "\n",
    "    # Create a directory for the letter if it doesn't exist\n",
    "    os.makedirs(letter, exist_ok=True)\n",
    "\n",
    "    # Iterate over each link\n",
    "    for link in links:\n",
    "        # Get the URL and the name of the link\n",
    "        url = link['href']\n",
    "        name = sanitize_file_name(link.text)\n",
    "\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # If the GET request is successful, the status code will be 200\n",
    "        if response.status_code == 200:\n",
    "            # Get the content of the response\n",
    "            page_content = response.content\n",
    "\n",
    "            # Create a BeautifulSoup object and specify the parser\n",
    "            soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "            # Extract all the text from the webpage\n",
    "            data = soup.get_text()\n",
    "\n",
    "            # Check if data is not empty\n",
    "            if data.strip():\n",
    "                # Save the data to a JSON file in the directory\n",
    "                with open(f\"{letter}/{name}.json\", 'w',  encoding='utf-8') as f:\n",
    "                    json.dump(data, f, indent=4)\n",
    "    url = None\n",
    "    name = None\n",
    "    response = None\n",
    "    page_content = None\n",
    "    soup = None\n",
    "    data = None    \n",
    "        \n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda16481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
